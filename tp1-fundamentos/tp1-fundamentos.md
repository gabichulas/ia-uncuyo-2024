2. a. El paper finaliza con la oración "Before allowing the language of consciousness to wander too far from its original home in human affairs, we would do well to remember that, though capable of humanlike behaviour, generative AI is otherwise not remotely human-like.", por lo que queda claro la posición de los autores. Creo que realmente es así, y la comparación de un LLM con el "role-play" me parece muy interesante. Es muy importante no darle autoridad a lo que generan estos modelos, y es algo que, lamentablemente, se hace mucho hoy en día. Se le da una importancia desmedida a una "opinión" de un algoritmo sobre hechos de la vida real, lo cual me parece cuanto menos utópico y sin sentido. Estas herramientas no están ni cerca de ser conscientes.

  b. Creo que la consecuencia más importante de ésto sería que los pondríamos a la altura de los seres conscientes ya conocidos, o sea, nosotros. Esto no es solo un problema moral o ético, sino que también, por ejemplo, legal. Tendría muchas implicancias negativas que definitivamente cambiarían el mundo en muchas formas.



3. Principalmente, creo que no es bueno para nadie tener una visión tan apocalíptica de la IA (y de la vida en general). Considero que Bender tiene razón en ciertas cosas, pero también se contradice en muchas otras. Por dar un ejemplo, se menciona: "LLMs, he acknowledged, are not human — **yet**.". Esto no tiene mucho sentido si tenemos en cuenta que fue ella quien acuñó el término "stochastic parrot", el cual describe metafóricamente el comportamiento de un LLM, que no tiene ningún tipo de conciencia, sino que es simplemente un algoritmo que dado un contexto y una gran base de conocimiento intenta predecir la siguiente palabra en una cadena de texto. 

Creo que estos modelos pueden ser peligrosos en las manos equivocadas — como cualquier herramienta — pero definitivamente no son un ente maligno que va a dominarnos algún día. Es muy importante que la gente entienda, de alguna forma, que estos algoritmos no tienen ni pueden tener autonomía o pensamientos propios. No pueden tomar decisiones (hablando fuera del concepto propio del algoritmo, que obviamente decide, en este caso, qué palabra sigue en un texto) ni conspirar contra nosotros. Son simplemente algoritmos. Pueden sernos o no útiles, pero pensar que son algún tipo de arma es algo que no le aporta nada a nadie.
.
