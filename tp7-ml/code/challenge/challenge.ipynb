{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/lopez/AppData/Local/R/win-library/4.4'\n",
      "(as 'lib' is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'randomForest' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\lopez\\AppData\\Local\\Temp\\RtmpC81pUc\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(e1071)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df <- read_csv('https://raw.githubusercontent.com/gabichulas/ia-uncuyo-2024/refs/heads/main/tp7-ml/data/arbolado-mendoza-dataset-train.csv', show_col_types = FALSE)\n",
    "test_df <- read_csv('https://raw.githubusercontent.com/gabichulas/ia-uncuyo-2024/refs/heads/main/tp7-ml/data/arbolado-mza-dataset-test.csv', show_col_types = FALSE)\n",
    "val_df <- read_csv('https://raw.githubusercontent.com/gabichulas/ia-uncuyo-2024/refs/heads/main/tp7-ml/data/arbolado-mendoza-dataset-validation.csv', show_col_types = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1 \n",
       "22633 22633 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_1 <- df[df$inclinacion_peligrosa == 1, ]\n",
    "set_0 <- df[df$inclinacion_peligrosa == 0, ]\n",
    "\n",
    "# Sobremuestrear la clase minoritaria\n",
    "set_1_over <- set_1 %>% sample_n(nrow(set_0), replace = TRUE)\n",
    "data <- rbind(set_1_over, set_0)\n",
    "table(data$inclinacion_peligrosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x <- data[, !(colnames(data) %in% c(\"inclinacion_peligrosa\", \"id\", \"area_seccion\",\"seccion\", \"ultima_modificacion\"))]\n",
    "y <- factor(data$inclinacion_peligrosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      " randomForest(x = x, y = y, ntree = 900, mtry = 2) \n",
      "               Type of random forest: classification\n",
      "                     Number of trees: 900\n",
      "No. of variables tried at each split: 2\n",
      "\n",
      "        OOB estimate of  error rate: 12.53%\n",
      "Confusion matrix:\n",
      "      0     1 class.error\n",
      "0 17217  5416   0.2392966\n",
      "1   257 22376   0.0113551\n",
      "         Actual\n",
      "Predicted    0    1\n",
      "        0 5559  646\n",
      "        1  139   38\n",
      "Precisión:  0.8769978 \n",
      "Recall:  0.8958904 0.2146893 \n",
      "F1-Score:  0.8863434 0.3449377 \n"
     ]
    }
   ],
   "source": [
    "model <- randomForest(x = x, y = y, ntree = 900, mtry = 2)\n",
    "print(model)\n",
    "\n",
    "predicciones_test <- predict(model, newdata = val_df)\n",
    "\n",
    "# Obtener las etiquetas verdaderas del conjunto de prueba\n",
    "etiquetas_reales_test <- val_df$inclinacion_peligrosa  # Reemplaza 'inclinacion_peligrosa' con el nombre de la columna de etiquetas\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "confusion_matrix_test <- table(Predicted = predicciones_test, Actual = etiquetas_reales_test)\n",
    "\n",
    "# Calcular precisión, recall y F1-score\n",
    "precision <- sum(diag(confusion_matrix_test)) / sum(confusion_matrix_test)\n",
    "recall <- diag(confusion_matrix_test) / rowSums(confusion_matrix_test)\n",
    "f1_score <- 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Imprimir la matriz de confusión y las métricas\n",
    "print(confusion_matrix_test)\n",
    "cat(\"Precisión: \", precision, \"\\n\")\n",
    "cat(\"Recall: \", recall, \"\\n\")\n",
    "cat(\"F1-Score: \", f1_score, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Predicciones guardadas en submission.csv\"\n"
     ]
    }
   ],
   "source": [
    "predicciones <- predict(model, newdata = test_df)\n",
    "\n",
    "submission <- data.frame(ID = test_df$id, inclinacion_peligrosa = predicciones)\n",
    "\n",
    "write.csv(submission, file = \"submission.csv\", row.names = FALSE)\n",
    "\n",
    "print(\"Predicciones guardadas en submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
